{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../../core/python-ocr/utils')\n",
    "sys.path.append('../../core/python-ocr/')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import load_image, convert_to_grayscale, resize_image\n",
    "from preprocessing.image_preprocessor import reduce_noise, enhance_contrast, preprocess_image\n",
    "from config import TEST_IMAGES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEST_IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_noise_reduction_comparison(images, func, max_images=5):\n",
    "    \"\"\"\n",
    "    Display noise reduction experiments for multiple images.\n",
    "    Each image gets its own row showing: Original, Gaussian, Bilateral, Combined\n",
    "    \"\"\"\n",
    "    n_images = min(len(images), max_images)  # Limit to avoid overcrowding\n",
    "    titles = ['Original', 'Gaussian', 'Bilateral', 'Gaussian + Bilateral']\n",
    "\n",
    "    fig, axes = plt.subplots(n_images, 4, figsize=(20, 5 * n_images))\n",
    "\n",
    "    # Handle case where there's only one image (axes won't be 2D)\n",
    "    if n_images == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for row, image in enumerate(images[:n_images]):\n",
    "        # Apply noise reduction experiments\n",
    "        i0, i1, i2, i3 = func(image)\n",
    "        processed_images = [i0, i1, i2, i3]\n",
    "\n",
    "        for col, (processed_img, title) in enumerate(zip(processed_images, titles)):\n",
    "            axes[row, col].imshow(processed_img, cmap='gray')\n",
    "            axes[row, col].set_title(f'Image {row+1}: {title}')\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_processing_comparison(images, processing_func, titles=None, max_images=5,\n",
    "                                figsize_per_image=5, cmap=None):\n",
    "    \"\"\"\n",
    "    Adaptive display function that works with any processing function.\n",
    "    Automatically detects the number of returned images and adjusts the layout.\n",
    "\n",
    "    Args:\n",
    "        images: List of input images\n",
    "        processing_func: Function that processes an image and returns multiple results\n",
    "        titles: List of titles for each processed image. If None, auto-generates titles\n",
    "        max_images: Maximum number of images to display\n",
    "        figsize_per_image: Height per image row in the figure\n",
    "        cmap: Colormap to use for all images (default: 'gray')\n",
    "    \"\"\"\n",
    "    if not images:\n",
    "        print(\"No images provided!\")\n",
    "        return\n",
    "\n",
    "    # Test the function with the first image to determine number of outputs\n",
    "    test_result = processing_func(images[0])\n",
    "\n",
    "    # Handle case where function returns a single image vs multiple images\n",
    "    if isinstance(test_result, (list, tuple)):\n",
    "        n_outputs = len(test_result)\n",
    "        processed_images = test_result\n",
    "    else:\n",
    "        # Single output case\n",
    "        n_outputs = 1\n",
    "        processed_images = [test_result]\n",
    "\n",
    "    # Generate default titles if not provided\n",
    "    if titles is None:\n",
    "        if n_outputs == 1:\n",
    "            titles = ['Processed']\n",
    "        elif n_outputs == 2:\n",
    "            titles = ['Method 1', 'Method 2']\n",
    "        elif n_outputs == 3:\n",
    "            titles = ['Method 1', 'Method 2', 'Method 3']\n",
    "        elif n_outputs == 4:\n",
    "            titles = ['Original', 'Method 1', 'Method 2', 'Combined']\n",
    "        elif n_outputs == 5:\n",
    "            titles = ['Original', 'Method 1', 'Method 2', 'Method 3', 'Combined']\n",
    "        else:\n",
    "            titles = [f'Output {i+1}' for i in range(n_outputs)]\n",
    "\n",
    "    # Ensure titles list matches number of outputs\n",
    "    if len(titles) != n_outputs:\n",
    "        print(f\"Warning: {len(titles)} titles provided but function returns {n_outputs} images.\")\n",
    "        titles = titles[:n_outputs] + [f'Output {i+1}' for i in range(len(titles), n_outputs)]\n",
    "\n",
    "    n_images = min(len(images), max_images)\n",
    "\n",
    "    # Create figure with adaptive size\n",
    "    fig, axes = plt.subplots(n_images, n_outputs,\n",
    "                            figsize=(4 * n_outputs, figsize_per_image * n_images))\n",
    "\n",
    "    # Handle different subplot configurations\n",
    "    if n_images == 1 and n_outputs == 1:\n",
    "        axes = [[axes]]  # Make it 2D for consistent indexing\n",
    "    elif n_images == 1:\n",
    "        axes = [axes]  # Make it 2D for consistent indexing\n",
    "    elif n_outputs == 1:\n",
    "        axes = [[ax] for ax in axes]  # Make it 2D for consistent indexing\n",
    "\n",
    "    # Process and display each image\n",
    "    for row, image in enumerate(images[:n_images]):\n",
    "        # Apply the processing function\n",
    "        result = processing_func(image)\n",
    "\n",
    "        # Handle single vs multiple outputs\n",
    "        if isinstance(result, (list, tuple)):\n",
    "            processed_imgs = result\n",
    "        else:\n",
    "            processed_imgs = [result]\n",
    "\n",
    "        # Display each processed image\n",
    "        for col, (processed_img, title) in enumerate(zip(processed_imgs, titles)):\n",
    "            axes[row][col].imshow(processed_img, cmap=cmap)\n",
    "\n",
    "            # Add title (only on first row to avoid clutter)\n",
    "            if row == 0:\n",
    "                axes[row][col].set_title(title, fontsize=12)\n",
    "\n",
    "            axes[row][col].axis('off')\n",
    "\n",
    "            # Add image number label on the left\n",
    "            if col == 0:\n",
    "                axes[row][col].set_ylabel(f'Image {row+1}', rotation=90,\n",
    "                                        fontsize=10, labelpad=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary information\n",
    "    print(f\"Displayed {n_images} images with {n_outputs} processing methods each.\")\n",
    "    if hasattr(processing_func, '__name__'):\n",
    "        print(f\"Processing function: {processing_func.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lenna = TEST_IMAGES_DIR / \"lenna.png\"\n",
    "path_lenna_noise = TEST_IMAGES_DIR / \"lenna_noise_grayscale.png\"\n",
    "path_clograd_noise = TEST_IMAGES_DIR / \"clogard_noise.png\"\n",
    "\n",
    "path_img_1 = TEST_IMAGES_DIR / \"1.jpg\"\n",
    "path_img_2 = TEST_IMAGES_DIR / \"2.jpg\"\n",
    "path_img_3 = TEST_IMAGES_DIR / \"3.jpg\"\n",
    "path_img_4 = TEST_IMAGES_DIR / \"4.jpg\"\n",
    "\n",
    "path_images = [path_img_1, path_img_2, path_img_3, path_img_4, path_lenna_noise]\n",
    "\n",
    "images = [resize_image(convert_to_grayscale(load_image(image)), max_width=512, max_height=512) for image in path_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_reduce_noise(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply noise reduction filters\"\"\"\n",
    "\n",
    "    kernel = (5, 5)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(image, kernel, 0)\n",
    "\n",
    "    denoised = cv2.bilateralFilter(image, 3, 40, 40)\n",
    "\n",
    "    both = cv2.bilateralFilter(blurred, 9, 100, 100)\n",
    "\n",
    "    return image, blurred, denoised, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = images[0]\n",
    "\n",
    "\n",
    "i0, i1, i2, i3 = experiment_reduce_noise(image)\n",
    "\n",
    "_, (p0, p1, p2, p3) = plt.subplots(1, 4, figsize= (20, 5))\n",
    "\n",
    "p0.imshow(i0, cmap='gray')\n",
    "p0.set_title('Original')\n",
    "\n",
    "p1.imshow(i1, cmap='gray')\n",
    "p1.set_title('Guassian')\n",
    "\n",
    "p2.imshow(i2, cmap='gray')\n",
    "p2.set_title('Bilteral')\n",
    "\n",
    "p3.imshow(i3, cmap='gray')\n",
    "p3.set_title('Gaussian + Biliteral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_noise_reduction_comparison(images, experiment_reduce_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_processing_comparison(images, reduce_noise, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_enahnce_contrast(image: np.ndarray):\n",
    "\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab_image) # split the channels\n",
    "\n",
    "    equ = cv2.equalizeHist(l) # only equalizing the luminosity\n",
    "    hist_equist = cv2.cvtColor(cv2.merge((equ, a, b)), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    ## CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_channel = clahe.apply(l)\n",
    "\n",
    "    clahe_img  = cv2.cvtColor(cv2.merge((clahe_channel, a, b)), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return image, hist_equist, clahe_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(path_lenna)\n",
    "display_processing_comparison([image], experiment_enahnce_contrast, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "l, a, b = cv2.split(lab_image) # split the channels\n",
    "\n",
    "equ = cv2.equalizeHist(l) # only equalizing the luminosity\n",
    "\n",
    "plt.hist(equ.flat, bins=100, range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_processing_comparison(images, enhance_contrast, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_processing_comparison(images, preprocess_image, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
